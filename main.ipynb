{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "<span style=\"font-family:Lucida Bright;\">\n",
    "<p style=\"margin-bottom:0.5cm\"></p>\n",
    "<center>\n",
    "<font size=\"8\"><b>Deep Learning, Fall 2021</b></font>\n",
    "<p style=\"margin-bottom:0.6cm\"></p>\n",
    "<font size=\"3\"><b>Final Project:</b></font>\n",
    "<p style=\"margin-bottom:0.6cm\"></p>\n",
    "<font size=\"5\"><b>Enhancing Voices for Better Speech Intelligibility</b></font>\n",
    "<p style=\"margin-bottom:2cm\"></p>\n",
    "<font size=\"6\"><b>Start</b></font>\n",
    "</center>\n",
    "<p style=\"margin-bottom:2cm\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialization\" data-toc-modified-id=\"Initialization-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Initialization</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Load data</a></span></li></ul></li><li><span><a href=\"#Load-wav-file\" data-toc-modified-id=\"Load-wav-file-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load wav file</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, we will blah blah"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## How to get the most out of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To fully enjoy the content of this notebook, please take note of the following:\n",
    "\n",
    "- The outputs of pre-executed cells will not be rendered properly unless the notebook is **Trusted**.\n",
    "\n",
    "- To avoid accidental changes, most of the cells in this notebook are marked-as read only, and many are frozen (i.e. disabled from being run). To take advantage of these features, it is recommended to use the extension\n",
    "[Freeze Cell](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/freeze/readme.html)  which works with Jupyter Notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prerequisites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is a part of project. To be able to execute all of its content:\n",
    "\n",
    "1. Download the project repository: `https://github.com/wojciechdk/deep-learning-2021-final-project.git` and run the notebook from the root.\n",
    "\n",
    "2. Download the [TIMIT dataset](https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3), unpack it, and place it so that the folders *DOC*, *TEST*, and *TRAIN* are placed in the folder `[root]\\resources\\data\\TIMIT`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Links and resources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- If you are reading the HTML version of this notebook and would like to download the ipynb source, you can do it [here](https://github.com/wojciechdk/deep-learning-2021-final-project/blob/main/main.ipynb).\n",
    "\n",
    "- The Git repository containing the entire project can be accessed [here](https://github.com/wojciechdk/deep-learning-2021-final-project.git)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The entire initialization process, including:\n",
    " - imports of the necessary packages\n",
    " - configuration of the notebook and packages\n",
    " - imports of the toolbox functions\n",
    "\n",
    "is defined in the file [toolbox/initialization.py](toolbox/initialization.py)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from toolbox.initialization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TIMIT dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The metadata about the TIMIT dataset is loaded using the function `load_timit_data` defined in the module `toolbox\\data_loading.py`. Once loaded, the data is saved in the project cache as a Pandas dataframe. Let's load it and show a couple of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     sentence_number data_group        dialect gender speaker  \\\n3383            1745      train  New York City      F    SDJ0   \n1977             312      train  South Midland      F    JXP0   \n5517             314       test  South Midland      M    PLB0   \n1312            1333      train  North Midland      F    SJW0   \n5547             317       test  South Midland      M    ROA0   \n\n                      type                                               text  \\\n3383  phonetically-diverse  This one came a bit high at thirty thousand or...   \n1977  phonetically-compact  Those answers will be straightforward if you t...   \n5517  phonetically-compact  If people were more generous, there would be n...   \n1312  phonetically-diverse  X-ray films of the vertebral column showed pro...   \n5547  phonetically-compact      The cranberry bog gets very pretty in Autumn.   \n\n                      audio_path start_sample end_sample  \\\n3383  train\\DR6\\FSDJ0\\SI1745.wav            0      41576   \n1977   train\\DR4\\FJXP0\\SX312.wav            0      57038   \n5517    test\\DR4\\MPLB0\\SX314.wav            0      62874   \n1312  train\\DR3\\FSJW0\\SI1333.wav            0      83252   \n5547    test\\DR4\\MROA0\\SX317.wav            0      39015   \n\n                                             words_text  \\\n3383  [this, one, came, a, bit, high, at, thirty, th...   \n1977  [those, answers, will, be, straightforward, if...   \n5517  [if, people, were, more, generous, there, woul...   \n1312  [x, ray, films, of, the, vertebral, column, sh...   \n5547  [the, cranberry, bog, gets, very, pretty, in, ...   \n\n                                     words_start_sample  \\\n3383  [2600, 5430, 7644, 11404, 12114, 14537, 19658,...   \n1977  [1880, 5013, 11240, 11947, 13480, 23000, 25640...   \n5517  [2040, 4760, 10760, 13891, 17683, 32830, 34840...   \n1312  [4120, 8280, 10920, 18130, 18715, 20428, 27560...   \n5547  [2840, 4052, 12520, 18966, 21681, 25240, 30872...   \n\n                                       words_end_sample  \\\n3383  [5430, 7644, 11404, 12114, 14537, 19658, 22840...   \n1977  [5013, 11240, 11947, 13480, 23000, 25640, 2660...   \n5517  [4760, 10760, 13891, 17683, 27560, 34840, 3809...   \n1312  [8280, 10920, 18130, 18715, 20428, 27560, 3560...   \n5547  [4052, 12520, 18966, 21681, 25240, 30872, 3242...   \n\n                                          phonemes_text  \\\n3383  [h#, dh, ih, s, w, ah, n, kcl, k, ey, m, ax, b...   \n1977  [h#, dh, ow, z, ae, n, s, axr, z, el, bcl, b, ...   \n5517  [h#, q, ih, f, pcl, p, iy, pcl, p, el, w, er, ...   \n1312  [h#, q, eh, kcl, k, s, r, ey, f, ih, l, m, z, ...   \n5547  [h#, dh, ix, kcl, k, r, ae, n, bcl, b, axr, iy...   \n\n                                  phonemes_start_sample  \\\n3383  [0, 2600, 2840, 3640, 5430, 6093, 6976, 7644, ...   \n1977  [0, 1880, 2422, 4219, 5013, 7603, 7937, 9000, ...   \n5517  [0, 2040, 2731, 3560, 4760, 5820, 6260, 7754, ...   \n1312  [0, 4120, 4469, 5389, 6230, 6480, 8280, 9160, ...   \n5547  [0, 2840, 3592, 4052, 4887, 6266, 6725, 8360, ...   \n\n                                    phonemes_end_sample  \n3383  [2600, 2840, 3640, 5430, 6093, 6976, 7644, 800...  \n1977  [1880, 2422, 4219, 5013, 7603, 7937, 9000, 103...  \n5517  [2040, 2731, 3560, 4760, 5820, 6260, 7754, 893...  \n1312  [4120, 4469, 5389, 6230, 6480, 8280, 9160, 109...  \n5547  [2840, 3592, 4052, 4887, 6266, 6725, 8360, 908...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_number</th>\n      <th>data_group</th>\n      <th>dialect</th>\n      <th>gender</th>\n      <th>speaker</th>\n      <th>type</th>\n      <th>text</th>\n      <th>audio_path</th>\n      <th>start_sample</th>\n      <th>end_sample</th>\n      <th>words_text</th>\n      <th>words_start_sample</th>\n      <th>words_end_sample</th>\n      <th>phonemes_text</th>\n      <th>phonemes_start_sample</th>\n      <th>phonemes_end_sample</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3383</th>\n      <td>1745</td>\n      <td>train</td>\n      <td>New York City</td>\n      <td>F</td>\n      <td>SDJ0</td>\n      <td>phonetically-diverse</td>\n      <td>This one came a bit high at thirty thousand or...</td>\n      <td>train\\DR6\\FSDJ0\\SI1745.wav</td>\n      <td>0</td>\n      <td>41576</td>\n      <td>[this, one, came, a, bit, high, at, thirty, th...</td>\n      <td>[2600, 5430, 7644, 11404, 12114, 14537, 19658,...</td>\n      <td>[5430, 7644, 11404, 12114, 14537, 19658, 22840...</td>\n      <td>[h#, dh, ih, s, w, ah, n, kcl, k, ey, m, ax, b...</td>\n      <td>[0, 2600, 2840, 3640, 5430, 6093, 6976, 7644, ...</td>\n      <td>[2600, 2840, 3640, 5430, 6093, 6976, 7644, 800...</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>312</td>\n      <td>train</td>\n      <td>South Midland</td>\n      <td>F</td>\n      <td>JXP0</td>\n      <td>phonetically-compact</td>\n      <td>Those answers will be straightforward if you t...</td>\n      <td>train\\DR4\\FJXP0\\SX312.wav</td>\n      <td>0</td>\n      <td>57038</td>\n      <td>[those, answers, will, be, straightforward, if...</td>\n      <td>[1880, 5013, 11240, 11947, 13480, 23000, 25640...</td>\n      <td>[5013, 11240, 11947, 13480, 23000, 25640, 2660...</td>\n      <td>[h#, dh, ow, z, ae, n, s, axr, z, el, bcl, b, ...</td>\n      <td>[0, 1880, 2422, 4219, 5013, 7603, 7937, 9000, ...</td>\n      <td>[1880, 2422, 4219, 5013, 7603, 7937, 9000, 103...</td>\n    </tr>\n    <tr>\n      <th>5517</th>\n      <td>314</td>\n      <td>test</td>\n      <td>South Midland</td>\n      <td>M</td>\n      <td>PLB0</td>\n      <td>phonetically-compact</td>\n      <td>If people were more generous, there would be n...</td>\n      <td>test\\DR4\\MPLB0\\SX314.wav</td>\n      <td>0</td>\n      <td>62874</td>\n      <td>[if, people, were, more, generous, there, woul...</td>\n      <td>[2040, 4760, 10760, 13891, 17683, 32830, 34840...</td>\n      <td>[4760, 10760, 13891, 17683, 27560, 34840, 3809...</td>\n      <td>[h#, q, ih, f, pcl, p, iy, pcl, p, el, w, er, ...</td>\n      <td>[0, 2040, 2731, 3560, 4760, 5820, 6260, 7754, ...</td>\n      <td>[2040, 2731, 3560, 4760, 5820, 6260, 7754, 893...</td>\n    </tr>\n    <tr>\n      <th>1312</th>\n      <td>1333</td>\n      <td>train</td>\n      <td>North Midland</td>\n      <td>F</td>\n      <td>SJW0</td>\n      <td>phonetically-diverse</td>\n      <td>X-ray films of the vertebral column showed pro...</td>\n      <td>train\\DR3\\FSJW0\\SI1333.wav</td>\n      <td>0</td>\n      <td>83252</td>\n      <td>[x, ray, films, of, the, vertebral, column, sh...</td>\n      <td>[4120, 8280, 10920, 18130, 18715, 20428, 27560...</td>\n      <td>[8280, 10920, 18130, 18715, 20428, 27560, 3560...</td>\n      <td>[h#, q, eh, kcl, k, s, r, ey, f, ih, l, m, z, ...</td>\n      <td>[0, 4120, 4469, 5389, 6230, 6480, 8280, 9160, ...</td>\n      <td>[4120, 4469, 5389, 6230, 6480, 8280, 9160, 109...</td>\n    </tr>\n    <tr>\n      <th>5547</th>\n      <td>317</td>\n      <td>test</td>\n      <td>South Midland</td>\n      <td>M</td>\n      <td>ROA0</td>\n      <td>phonetically-compact</td>\n      <td>The cranberry bog gets very pretty in Autumn.</td>\n      <td>test\\DR4\\MROA0\\SX317.wav</td>\n      <td>0</td>\n      <td>39015</td>\n      <td>[the, cranberry, bog, gets, very, pretty, in, ...</td>\n      <td>[2840, 4052, 12520, 18966, 21681, 25240, 30872...</td>\n      <td>[4052, 12520, 18966, 21681, 25240, 30872, 3242...</td>\n      <td>[h#, dh, ix, kcl, k, r, ae, n, bcl, b, axr, iy...</td>\n      <td>[0, 2840, 3592, 4052, 4887, 6266, 6725, 8360, ...</td>\n      <td>[2840, 3592, 4052, 4887, 6266, 6725, 8360, 908...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TIMIT meta data from the cache.\n",
    "df_timit = pd.read_pickle(paths.cache.df_timit)\n",
    "\n",
    "# Show the top 5 rows\n",
    "display(df_timit.sample(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's play one sentence from the dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "t.sound.play_timit(df_timit.loc[0, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Synthetic speech dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metadata about the dataset containing synthetic speech in different audio settings is loaded using the function `load_synthetic_speech_data` defined in the module `toolbox\\data_loading.py`. Once loaded, the data is saved in the project cache as a Pandas dataframe. Let's load it and show a couple of rows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       speaker length         variant segment fullness clarity  \\\n2582  kimberly     5s       distorted      38      NaN     NaN   \n1728    kendra     5s  zoom_augmented      26        4       1   \n2575  kimberly   full       distorted     NaN      NaN     NaN   \n1583    justin     5s           clean      37      NaN     NaN   \n500     joanna     5s  zoom_augmented      34        4       1   \n\n                         audio_path  \n2582   cut_5_s\\kimberly\\bitc\\38.wav  \n1728      cut_5_s\\kendra\\4-1\\26.wav  \n2575  full_length\\kimberly\\bitc.wav  \n1583     cut_5_s\\justin\\orig\\37.wav  \n500       cut_5_s\\joanna\\4-1\\34.wav  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker</th>\n      <th>length</th>\n      <th>variant</th>\n      <th>segment</th>\n      <th>fullness</th>\n      <th>clarity</th>\n      <th>audio_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2582</th>\n      <td>kimberly</td>\n      <td>5s</td>\n      <td>distorted</td>\n      <td>38</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>cut_5_s\\kimberly\\bitc\\38.wav</td>\n    </tr>\n    <tr>\n      <th>1728</th>\n      <td>kendra</td>\n      <td>5s</td>\n      <td>zoom_augmented</td>\n      <td>26</td>\n      <td>4</td>\n      <td>1</td>\n      <td>cut_5_s\\kendra\\4-1\\26.wav</td>\n    </tr>\n    <tr>\n      <th>2575</th>\n      <td>kimberly</td>\n      <td>full</td>\n      <td>distorted</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>full_length\\kimberly\\bitc.wav</td>\n    </tr>\n    <tr>\n      <th>1583</th>\n      <td>justin</td>\n      <td>5s</td>\n      <td>clean</td>\n      <td>37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>cut_5_s\\justin\\orig\\37.wav</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>joanna</td>\n      <td>5s</td>\n      <td>zoom_augmented</td>\n      <td>34</td>\n      <td>4</td>\n      <td>1</td>\n      <td>cut_5_s\\joanna\\4-1\\34.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the meta data about the synthetic speech dataset from the cache.\n",
    "df_synthetic_speech = pd.read_pickle(paths.cache.df_synthetic_speech)\n",
    "\n",
    "# Show the top 5 rows.\n",
    "display(df_synthetic_speech.sample(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's play one of the first 5s segments from the database:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    speaker length variant segment fullness clarity  \\\n559  joanna     5s  babble      10      NaN     NaN   \n\n                     audio_path  \n559  cut_5_s\\joanna\\babb\\10.wav  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker</th>\n      <th>length</th>\n      <th>variant</th>\n      <th>segment</th>\n      <th>fullness</th>\n      <th>clarity</th>\n      <th>audio_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>559</th>\n      <td>joanna</td>\n      <td>5s</td>\n      <td>babble</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>cut_5_s\\joanna\\babb\\10.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose which file to play.\n",
    "mask = (\n",
    "    (df_synthetic_speech['speaker'] == 'joanna')\n",
    "    & (df_synthetic_speech['length'] == '5s')\n",
    "    & (df_synthetic_speech['segment'] == 10)\n",
    "    & (df_synthetic_speech['variant'] == 'babble')\n",
    ")\n",
    "\n",
    "display(\n",
    "    df_synthetic_speech.loc[mask, :]\n",
    ")\n",
    "\n",
    "# Play.\n",
    "t.sound.play_synthetic_speech(df_synthetic_speech.loc[mask, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DataScience] *",
   "language": "python",
   "name": "conda-env-.conda-DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "445px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "093e89bffde74c5a8863a1d8ffe0bb66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1a5365fd770e464891fe02b94cb34b95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1c7a498865af41a1bd4af63eca07bd28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatTextModel",
      "state": {
       "layout": "IPY_MODEL_68759d18977d4757ba3eb3cf81aa1129",
       "step": null,
       "style": "IPY_MODEL_feea9000784940f3b601fd1ba613dd31"
      }
     },
     "1ee2806f2e314951b8b42666540f6aee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "371339a327cc48d8a56358f512674975": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "65604f719f9e41f3b6d495d3aa907529": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "68759d18977d4757ba3eb3cf81aa1129": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "68dd48c190fe4b8c92790dc65803d785": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DropdownModel",
      "state": {
       "_options_labels": [
        "One",
        "Two",
        "Three"
       ],
       "description": "Number:",
       "index": 1,
       "layout": "IPY_MODEL_371339a327cc48d8a56358f512674975",
       "style": "IPY_MODEL_89e645fe88da40b2890bc1c08b50be78"
      }
     },
     "839595af423541ef946ce08e437e5b7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "89e645fe88da40b2890bc1c08b50be78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9091258d01434bf8ac0f41c12363e6a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatTextModel",
      "state": {
       "layout": "IPY_MODEL_c22c18c67fe24f06ada7d28e3cb6ff90",
       "step": null,
       "style": "IPY_MODEL_839595af423541ef946ce08e437e5b7e"
      }
     },
     "afadc0b9a4f3458685319c1818955895": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DropdownModel",
      "state": {
       "_options_labels": [
        "One",
        "Two",
        "Three"
       ],
       "description": "Number:",
       "index": 1,
       "layout": "IPY_MODEL_1ee2806f2e314951b8b42666540f6aee",
       "style": "IPY_MODEL_093e89bffde74c5a8863a1d8ffe0bb66"
      }
     },
     "c22c18c67fe24f06ada7d28e3cb6ff90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c64dd728486c4d4396b6b2b4a02ca054": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatSliderModel",
      "state": {
       "layout": "IPY_MODEL_1a5365fd770e464891fe02b94cb34b95",
       "step": 0.1,
       "style": "IPY_MODEL_ff2f617f26294276834c51733d0f253c"
      }
     },
     "d7c60be1aeb643fe9d80a622e61b4cc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fe21ecb1be5e431c9745cf04421dc9a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatSliderModel",
      "state": {
       "layout": "IPY_MODEL_d7c60be1aeb643fe9d80a622e61b4cc2",
       "step": 0.1,
       "style": "IPY_MODEL_65604f719f9e41f3b6d495d3aa907529",
       "value": 55.4
      }
     },
     "feea9000784940f3b601fd1ba613dd31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ff2f617f26294276834c51733d0f253c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}